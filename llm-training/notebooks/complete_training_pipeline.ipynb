{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Exoplanet LLM Training Pipeline\n",
        "\n",
        "This notebook provides a complete walkthrough of training an LLM for exoplanet reasoning using Unsloth and GRPO.\n",
        "\n",
        "## Overview\n",
        "1. **Environment Setup** - Check dependencies and hardware\n",
        "2. **Data Preparation** - Create and process training datasets\n",
        "3. **Model Fine-tuning** - Supervised fine-tuning with Unsloth\n",
        "4. **GRPO Training** - Reasoning enhancement with reinforcement learning\n",
        "5. **Evaluation** - Comprehensive model assessment\n",
        "6. **Inference** - Interactive testing and deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check environment\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"üêç Python version: {sys.version}\")\n",
        "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
        "print(f\"üöÄ CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üíæ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üî¢ CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"üíΩ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è CUDA not available - training will be slower\")\n",
        "\n",
        "# Set working directory\n",
        "os.chdir('/Users/manmathmohanty/Desktop/untitled folder 18')\n",
        "print(f\"üìÅ Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preparation\n",
        "\n",
        "Let's create our exoplanet training dataset with Q&A pairs and reasoning prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the dataset\n",
        "!python scripts/prepare_dataset.py --output data/processed/\n",
        "\n",
        "# Check what was created\n",
        "import json\n",
        "\n",
        "# Load and inspect the dataset\n",
        "with open('data/processed/combined_dataset.json', 'r') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "print(f\"üìä Total examples: {len(dataset)}\")\n",
        "\n",
        "# Show category breakdown\n",
        "categories = {}\n",
        "for item in dataset:\n",
        "    cat = item.get('category', 'unknown')\n",
        "    categories[cat] = categories.get(cat, 0) + 1\n",
        "\n",
        "for cat, count in categories.items():\n",
        "    print(f\"  {cat}: {count} examples\")\n",
        "\n",
        "# Show a sample\n",
        "print(\"\\nüìù Sample Q&A:\")\n",
        "sample = dataset[0]\n",
        "print(f\"Q: {sample['messages'][0]['content']}\")\n",
        "print(f\"A: {sample['messages'][1]['content'][:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Fine-tuning with Unsloth\n",
        "\n",
        "Now let's fine-tune a base model on our exoplanet dataset using Unsloth for 2x faster training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tune the model (reduced steps for notebook demo)\n",
        "!python train/finetune.py \\\n",
        "    --model llama-3-8b-instruct \\\n",
        "    --dataset data/processed/combined_dataset.json \\\n",
        "    --output_dir outputs/finetuned_model \\\n",
        "    --max_steps 30 \\\n",
        "    --batch_size 2 \\\n",
        "    --learning_rate 2e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Test the Fine-tuned Model\n",
        "\n",
        "Let's test our fine-tuned model before applying GRPO training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick test of the fine-tuned model\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"outputs/finetuned_model\",\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Test with a sample question\n",
        "def test_model(question):\n",
        "    prompt = f\"Human: {question}\\nAssistant: \"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    \n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response[len(prompt):].strip()\n",
        "\n",
        "# Test questions\n",
        "test_questions = [\n",
        "    \"What is the transit method for detecting exoplanets?\",\n",
        "    \"How do we determine if an exoplanet is habitable?\"\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    print(f\"\\n‚ùì {q}\")\n",
        "    print(f\"ü§ñ {test_model(q)}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. GRPO Reasoning Training\n",
        "\n",
        "Now let's enhance the model's reasoning capabilities using GRPO (Group Relative Policy Optimization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply GRPO training for reasoning enhancement\n",
        "!python train/grpo_reasoning.py \\\n",
        "    --base_model outputs/finetuned_model \\\n",
        "    --output_dir outputs/grpo_model \\\n",
        "    --steps 50 \\\n",
        "    --batch_size 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation\n",
        "\n",
        "Let's comprehensively evaluate our trained model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the final model\n",
        "!python evaluation/evaluate_model.py \\\n",
        "    --model outputs/finetuned_model \\\n",
        "    --output evaluation_results.json \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Interactive Testing\n",
        "\n",
        "Let's test our model interactively with some challenging exoplanet questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive testing with the trained model\n",
        "from inference.chat_complete import ExoplanetChatBot\n",
        "\n",
        "# Initialize chatbot\n",
        "chatbot = ExoplanetChatBot(\"outputs/finetuned_model\", use_unsloth=True)\n",
        "\n",
        "# Test with complex reasoning questions\n",
        "complex_questions = [\n",
        "    \"Compare the advantages and limitations of the transit method versus radial velocity method for exoplanet detection.\",\n",
        "    \"Explain step-by-step how we would confirm that a potentially habitable exoplanet actually harbors life.\",\n",
        "    \"Why are hot Jupiters easier to detect than Earth-like planets, and what does this tell us about detection bias?\"\n",
        "]\n",
        "\n",
        "for i, question in enumerate(complex_questions, 1):\n",
        "    print(f\"\\nüß† Complex Question {i}:\")\n",
        "    print(f\"‚ùì {question}\")\n",
        "    print(f\"\\nü§ñ Response:\")\n",
        "    response = chatbot.generate_response(question, max_length=400)\n",
        "    print(response)\n",
        "    print(\"\\n\" + \"=\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Performance Analysis\n",
        "\n",
        "Let's analyze the model's performance and create some visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and analyze evaluation results\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load evaluation results\n",
        "with open('evaluation_results.json', 'r') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "# Create performance visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "fig.suptitle('Exoplanet LLM Performance Analysis', fontsize=16)\n",
        "\n",
        "# Performance metrics\n",
        "metrics = {\n",
        "    'Factual Accuracy': results['factual_accuracy'],\n",
        "    'Reasoning Quality': results['reasoning_quality'],\n",
        "    'Scientific Terminology': results['scientific_terminology'] / 5,  # Normalize\n",
        "    'Coherence Score': results['coherence_score'] / 3  # Normalize\n",
        "}\n",
        "\n",
        "# Bar chart of main metrics\n",
        "axes[0, 0].bar(metrics.keys(), metrics.values(), color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
        "axes[0, 0].set_title('Overall Performance Metrics')\n",
        "axes[0, 0].set_ylabel('Score')\n",
        "axes[0, 0].set_ylim(0, 1)\n",
        "\n",
        "# Response length distribution\n",
        "response_lengths = [r['word_count'] for r in results['detailed_results']['quality']['responses']]\n",
        "axes[0, 1].hist(response_lengths, bins=10, color='#FFB6C1', alpha=0.7)\n",
        "axes[0, 1].set_title('Response Length Distribution')\n",
        "axes[0, 1].set_xlabel('Word Count')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "# Factual accuracy by category\n",
        "factual_results = results['detailed_results']['factual']['results']\n",
        "categories = {}\n",
        "for result in factual_results:\n",
        "    cat = result['category']\n",
        "    if cat not in categories:\n",
        "        categories[cat] = {'correct': 0, 'total': 0}\n",
        "    categories[cat]['total'] += 1\n",
        "    if result['correct']:\n",
        "        categories[cat]['correct'] += 1\n",
        "\n",
        "cat_names = list(categories.keys())\n",
        "cat_scores = [categories[cat]['correct'] / categories[cat]['total'] for cat in cat_names]\n",
        "\n",
        "axes[1, 0].bar(range(len(cat_names)), cat_scores, color='#DDA0DD')\n",
        "axes[1, 0].set_title('Accuracy by Category')\n",
        "axes[1, 0].set_xticks(range(len(cat_names)))\n",
        "axes[1, 0].set_xticklabels(cat_names, rotation=45, ha='right')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "\n",
        "# Overall score gauge\n",
        "overall_score = (results['factual_accuracy'] + results['reasoning_quality']) / 2\n",
        "colors = ['#FF6B6B', '#FFD93D', '#6BCF7F', '#4ECDC4']\n",
        "sizes = [overall_score, 1 - overall_score]\n",
        "axes[1, 1].pie([overall_score], colors=['#4ECDC4'], startangle=90, counterclock=False)\n",
        "axes[1, 1].add_patch(plt.Circle((0, 0), 0.7, color='white'))\n",
        "axes[1, 1].text(0, 0, f'{overall_score:.1%}\\nOverall\\nScore', \n",
        "                ha='center', va='center', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_title('Overall Performance')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_performance_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Performance Summary:\")\n",
        "print(f\"üéØ Overall Score: {overall_score:.1%}\")\n",
        "print(f\"üìö Factual Accuracy: {results['factual_accuracy']:.1%}\")\n",
        "print(f\"üß† Reasoning Quality: {results['reasoning_quality']:.1%}\")\n",
        "print(f\"üìù Avg Response Length: {results['avg_response_length']:.1f} words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Deployment Preparation\n",
        "\n",
        "Let's prepare our model for deployment and create a simple API interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model in different formats for deployment\n",
        "print(\"üíæ Preparing model for deployment...\")\n",
        "\n",
        "# Save model info\n",
        "model_info = {\n",
        "    \"model_name\": \"exoplanet-reasoning-llm\",\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"base_model\": \"llama-3-8b-instruct\",\n",
        "    \"training_date\": \"2025-10-02\",\n",
        "    \"performance\": {\n",
        "        \"factual_accuracy\": results['factual_accuracy'],\n",
        "        \"reasoning_quality\": results['reasoning_quality'],\n",
        "        \"overall_score\": overall_score\n",
        "    },\n",
        "    \"capabilities\": [\n",
        "        \"Exoplanet detection methods explanation\",\n",
        "        \"Habitability assessment\",\n",
        "        \"Scientific reasoning and analysis\",\n",
        "        \"Astronomical phenomena explanation\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open('outputs/model_info.json', 'w') as f:\n",
        "    json.dump(model_info, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Model information saved\")\n",
        "print(\"üìÅ Model ready for deployment in: outputs/finetuned_model/\")\n",
        "print(\"\\nüöÄ To deploy:\")\n",
        "print(\"1. Use inference/chat_complete.py for interactive chat\")\n",
        "print(\"2. Create API wrapper using FastAPI or Flask\")\n",
        "print(\"3. Deploy to cloud platforms like HuggingFace Spaces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Conclusion\n",
        "\n",
        "üéâ **Congratulations!** You've successfully created and trained an exoplanet reasoning LLM!\n",
        "\n",
        "### What we accomplished:\n",
        "- ‚úÖ Created a specialized dataset for exoplanet knowledge\n",
        "- ‚úÖ Fine-tuned a language model using Unsloth (2x faster training)\n",
        "- ‚úÖ Enhanced reasoning capabilities with GRPO training\n",
        "- ‚úÖ Evaluated model performance comprehensively\n",
        "- ‚úÖ Created interactive chat interface\n",
        "- ‚úÖ Prepared model for deployment\n",
        "\n",
        "### Key Features of Your Model:\n",
        "- üî¨ **Scientific Accuracy**: Trained on verified exoplanet knowledge\n",
        "- üß† **Enhanced Reasoning**: GRPO training for better logical thinking\n",
        "- üöÄ **Fast Inference**: Optimized with Unsloth for production use\n",
        "- üìä **Comprehensive Evaluation**: Tested on multiple metrics\n",
        "\n",
        "### Next Steps:\n",
        "1. **Expand Dataset**: Add more astronomical data and recent discoveries\n",
        "2. **Advanced Training**: Experiment with different GRPO configurations\n",
        "3. **Deployment**: Create API endpoints and web interfaces\n",
        "4. **Integration**: Connect with astronomical databases and tools\n",
        "\n",
        "Your exoplanet reasoning LLM is now ready to help researchers, students, and enthusiasts explore the fascinating world of exoplanets! üåü"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
